{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chia tập train, dev, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the subset by rating to create new train, val, and test splits\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "by_rating = collections.defaultdict(list)\n",
    "for _, row in review_subset.iterrows():\n",
    "    by_rating[row.rating].append(row.to_dict())\n",
    "    \n",
    "# Create split data\n",
    "final_list = []\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "for _, item_list in sorted(by_rating.items()):\n",
    "    np.random.shuffle(item_list)\n",
    "    n_total = len(item_list)\n",
    "    n_train = int(args.train_proportion * n_total)\n",
    "    n_val = int(args.val_proportion * n_total)\n",
    "    n_test = int(args.test_proportion * n_total)\n",
    "\n",
    "# Give data point a split attribute\n",
    "for item in item_list[:n_train]:\n",
    "    item['split'] = 'train'\n",
    "\n",
    "for item in item_list[n_train:n_train+n_val]:\n",
    "    item['split'] = 'val'\n",
    "\n",
    "for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
    "    item['split'] = 'test'\n",
    "\n",
    "# Add to final list\n",
    "final_list.extend(item_list)\n",
    "final_reviews = pd.DataFrame(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiền xử lý dữ liệu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a­zA­Z.,!?]+\", r\" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lớp xử lý dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, review_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        review_df (pandas.DataFrame): bộ dữ liệu\n",
    "        vectorizer (ReviewVectorizer): vecto được tạo từ bộ dữ liệu\n",
    "        \"\"\"\n",
    "        self.review_df = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "        self.train_df = self.review_df[self.review_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        self.val_df = self.review_df[self.review_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "        self.test_df = self.review_df[self.review_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                            'val': (self.val_df, self.validation_size),\n",
    "                            'test': (self.test_df, self.test_size)}\n",
    "        self.set_split('train')\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
    "        \"\"\"Load data và tạo vecto\n",
    "        Args:\n",
    "        review_csv (str): tập dữ liệu\n",
    "        Returns:\n",
    "        một biến với dạng ReviewVectorizer\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        return cls(review_df, ReviewVectorizer.from_dataframe(review_df))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns một vecto \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" chọn dữ liệu được chia theo các cột\n",
    "        Args:\n",
    "        split (str): one of \"train\", \"val\", or \"test\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"hàm chính trong lớp DataReview\n",
    "        Args:\n",
    "        index (int): index của data point\n",
    "        Returns:\n",
    "        một dictionary của một điểm dữ liệu\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        review_vector = \\\n",
    "        self._vectorizer.vectorize(row.review)\n",
    "        rating_index = \\\n",
    "        self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "        return {'x_data': review_vector,\n",
    "                'y_target': rating_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Cung cấp batch size, cung cấp số lượng batch trong tập data\n",
    "        Args:\n",
    "        batch_size (int)\n",
    "        Returns:\n",
    "        số lượng batch trong data\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lớp Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Lớp xử lý văn bản và tạo vocabulary từ việc thực hiện việc mapping các từ sang một số thực đại diện cho nó\"\"\"\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        token_to_idx (dict): một dictionary mapping sẵn giữa từ và số thực, key : chỉ số index, value : từ \n",
    "        add_unk (bool): xác định xem có thêm ký tự unk vào hay không\n",
    "        unk_token (str): ký tự unk \n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token\n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        self.unk_index = 1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\" một từ điển có thể xử lý tuần tự \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx,\n",
    "                'add_unk': self._add_unk,\n",
    "                'unk_token': self._unk_token}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" khởi tạo vocabulary từ dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\"mapping với từ mới\n",
    "        Args:\n",
    "        token (str): từ cần thêm vào vocabulary\n",
    "        Returns:\n",
    "        index (int): index của từ tương ứng\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Truy vấn index của một từ\n",
    "        Args:\n",
    "        token (str): từ cần truy vấn \n",
    "        Returns:\n",
    "        index (int): index ứng với từ cần truy vấn\n",
    "        Notes:\n",
    "        `unk_index` cần >=0 (unk đã được add vào trong vocabulary)\n",
    "        cho trường hợp từ đó không xuất hiện\n",
    "        \"\"\"\n",
    "        if self.add_unk:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"truy vấn từ dựa trên index\n",
    "        Args:\n",
    "        index (int): index của từ cần truy vấn\n",
    "        Returns:\n",
    "        token (str): từ cần truy vấn\n",
    "        Raises:\n",
    "        KeyError: nếu index không nằm trong từ điển\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lớp Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class ReviewVectorizer(object):\n",
    "    \"\"\" Vectorize sử dụng Vocabulary để tạo ra vecto\"\"\"\n",
    "    def __init__(self, review_vocab, rating_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        review_vocab (Vocabulary): map từ sang số nguyên\n",
    "        rating_vocab (Vocabulary): maps nhãn của lớp sang số nguyên\n",
    "        \"\"\"\n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab\n",
    "    def vectorize(self, review):\n",
    "        \"\"\"Tạo vecto onehot\n",
    "        Args:\n",
    "        review (str): văn bản\n",
    "        Returns:\n",
    "        one_hot (np.ndarray): vecto onehot\n",
    "        \"\"\"\n",
    "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
    "        for token in review.split(\" \"):\n",
    "            if token not in string.punctuation:\n",
    "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
    "        return one_hot\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, review_df, cutoff=25):\n",
    "        \"\"\"Tạo vecto từ dataframe\n",
    "        Args:\n",
    "        review_df (pandas.DataFrame): tập dữ liệu\n",
    "        cutoff (int): tham số cutoff\n",
    "        Returns:\n",
    "        Review_Vocabulary\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary(add_unk=True)\n",
    "        rating_vocab = Vocabulary(add_unk=False)\n",
    "\n",
    "        # Add ratings\n",
    "        for rating in sorted(set(review_df.rating)):\n",
    "            rating_vocab.add_token(rating)\n",
    "        # Add top words if count > provided count\n",
    "        word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            for word in review.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff:\n",
    "                review_vocab.add_token(word)\n",
    "        return cls(review_vocab, rating_vocab)\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\"Tuần tự hóa\n",
    "        Args:\n",
    "        contents (dict): dictionary đã được tuần tự hóa\n",
    "        Returns:\n",
    "        Review_Vocabulary\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\n",
    "        rating_vocab = Vocabulary.from_serializable(contents['rating_vocab'])\n",
    "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
    "    def to_serializable(self):\n",
    "        \"\"\"Tạo dictionary để xử lý tuần tự\n",
    "        Returns:\n",
    "        contents (dict): dictionary có thể tuần tự hóa\n",
    "        \"\"\"\n",
    "        return {'review_vocab': self.review_vocab.to_serializable(),\n",
    "        'rating_vocab': self.rating_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lớp Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "    drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    đảm bảo mỗi vecto nằm ở trên cpu\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "    shuffle=shuffle, drop_last=drop_last)\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng mạng nơ ron với cấu hình perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self, num_feature) :\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_features=num_feature, out_features=1)\n",
    "    \n",
    "    def forward(self,input,apply_sigmoid = False):\n",
    "        output = self.linear(input).squeeze()\n",
    "        if apply_sigmoid:\n",
    "            output = nn.Sigmoid(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    frequency_cutoff=25,\n",
    "    model_state_file='model.pth',\n",
    "    review_csv='data/yelp/reviews_with_splits_lite.csv',\n",
    "    save_dir='model_storage/ch3/yelp/',\n",
    "    vectorizer_file='vectorizer.json',\n",
    "    # No model hyperparameters\n",
    "    # Training hyperparameters\n",
    "    batch_size=128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    seed=1337,\n",
    "    # Runtime options omitted for space\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d65b2b009303c0af65e9c9d4be8f26c2c45182fd085ae18c2ed3b904a6fa84e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
